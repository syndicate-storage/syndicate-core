#!/usr/bin/env python

"""
   Copyright 2016 The Trustees of Princeton University

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
"""

"""
Filesystem AG driver.
Serves files on a remote system through generic fs plugin.
"""

import traceback
import sys
import os
import errno
import time
import threading
import Queue
import json
import syndicate.util.gateway as gateway
import sgfsdriver.lib.abstractfs as abstractfs

from sgfsdriver.lib.pluginloader import pluginloader

storage_dir = None
sync_fully = False
fs = None

# will store commands to be processed
command_queue = Queue.Queue(0)

DEFAULT_SCAN_FILE_TTL = 1000 * 60 * 5 # 5mins
DEFAULT_SCAN_DIRECTORY_TTL = 1000 # expire very soon
DEFAULT_REFRESH_FILE_TTL = 1000 * 60 * 5 # 5mins
DEFAULT_REFRESH_DIRECTORY_TTL = 1000 * 60 * 5 # 5 mins
DEFAULT_READ_TTL = 1000 * 60 *5 # 5min


def _initFS( driver_config, driver_secrets, role ):
    global fs
    global storage_dir
    global sync_fully

    if fs:
        return True

    # continue only when fs is not initialized
    if not driver_config.has_key( 'DRIVER_FS_PLUGIN' ):
        gateway.log_error( "No DRIVER_FS_PLUGIN defined" )
        return False

    if not driver_config.has_key( 'DRIVER_FS_PLUGIN_CONFIG' ):
        gateway.log_error( "No DRIVER_FS_PLUGIN_CONFIG defined" )
        return False

    if not driver_config.has_key('DATASET_DIR'):
        gateway.log_error( "No DATASET_DIR defined" )
        return False

    storage_dir = driver_config['DATASET_DIR']
    storage_dir = "/" + storage_dir.strip("/")

    if driver_config.has_key('DATASET_SYNC_FULLY'):
        sync_fully = driver_config['DATASET_SYNC_FULLY']
    else:
        sync_fully = True

    plugin = driver_config['DRIVER_FS_PLUGIN']

    if isinstance( driver_config['DRIVER_FS_PLUGIN_CONFIG'], dict ):
        plugin_config = driver_config['DRIVER_FS_PLUGIN_CONFIG']
    elif isinstance( driver_config['DRIVER_FS_PLUGIN_CONFIG'], basestring ):
        json_plugin_config = driver_config['DRIVER_FS_PLUGIN_CONFIG']
        plugin_config = json.loads( json_plugin_config )

    plugin_config["secrets"] = driver_secrets
    plugin_config["work_root"] = storage_dir

    try:
        loader = pluginloader()
        fs = loader.load( plugin, plugin_config, role )

        if not fs:
            gateway.log_error( "No such driver plugin found: %s" % plugin )
            return False

        fs.set_notification_cb(datasets_update_cb)
        fs.connect()
    except Exception as e:
        gateway.log_error( "Unable to initialize a driver" )
        gateway.log_error( str( e ) )
        traceback.print_exc()
        return False

    gateway.log_debug( "Driver initialized" )
    return True


def _shutdownFS():
    global fs
    if fs:
        try:
            fs.close()
        except Exception:
            pass
    fs = None


def datasets_update_cb( updated_entries, added_entries, removed_entries ):
    global command_queue

    for u in updated_entries:
        if u.stat and not u.stat.directory:
            # file
            cmd = gateway.make_metadata_command( "put", "file", 0555, u.stat.size, u.path, read_ttl=DEFAULT_READ_TTL, write_ttl=DEFAULT_SCAN_FILE_TTL )
            gateway.log_debug( "Queuing a command %s" % cmd['path'] )
            command_queue.put( (cmd, None) )
        else:
            # directory
            cmd = gateway.make_metadata_command( "put", "directory", 0555, None, u.path, read_ttl=DEFAULT_READ_TTL, write_ttl=DEFAULT_SCAN_DIRECTORY_TTL )
            gateway.log_debug( "Queuing a command %s" % cmd['path'] )
            command_queue.put( (cmd, None) )

    for a in added_entries:
        if a.stat and not a.stat.directory:
            # file
            cmd = gateway.make_metadata_command( "put", "file", 0555, a.stat.size, a.path, read_ttl=DEFAULT_READ_TTL, write_ttl=DEFAULT_SCAN_FILE_TTL )
            gateway.log_debug( "Queuing a command %s" % cmd['path'] )
            command_queue.put( (cmd, None) )
        else:
            # directory
            cmd = gateway.make_metadata_command( "put", "directory", 0555, None, a.path, read_ttl=DEFAULT_READ_TTL, write_ttl=DEFAULT_SCAN_DIRECTORY_TTL )
            gateway.log_debug( "Queuing a command %s" % cmd['path'] )
            command_queue.put( (cmd, None) )

    for r in removed_entries:
        cmd = gateway.make_metadata_delete_command( r.path )
        gateway.log_debug( "Queuing a command %s" % cmd['path'] )
        command_queue.put( (cmd, None) )


def _resync( path ):
    global fs
    global sync_fully

    stack = [path]
    while len( stack ) > 0:
        last_dir = stack.pop( 0 )
        fs.clear_cache( last_dir )
        entries = fs.list_dir( last_dir )
        if entries:
            for entry in entries:
                # entry is a filename
                entry_path = last_dir.rstrip( "/" ) + "/" + entry
                st = fs.stat( entry_path )
                e = abstractfs.afsevent( entry_path, st )

                if st.directory:
                    if sync_fully:
                        # do sync recursively
                        stack.append( entry_path )

                datasets_update_cb( [], [e], [] )


def driver_init( driver_config, driver_secrets ):
    """
    Do the one-time driver setup.
    """

    global fs
    global storage_dir

    # detect a role
    rolestr = sys.argv[1]
    role = abstractfs.afsrole.DISCOVER
    if rolestr == "read":
        role = abstractfs.afsrole.READ
    elif rolestr == "crawl":
        role = abstractfs.afsrole.DISCOVER
    else:
        gateway.log_error( "Unknown role: %s" % rolestr )
        return False

    if not _initFS( driver_config, driver_secrets, role ):
        gateway.log_error( "Unable to init filesystem")
        return False

    if not fs.exists( "/" ):
        gateway.log_error( "No such file or directory: %s" % storage_dir )
        return False

    if not fs.is_dir( "/" ):
        gateway.log_error( "Not a directory: %s" % storage_dir )
        return False

    if role == abstractfs.afsrole.DISCOVER:
        # add initial dataset
        _resync( "/" )

    return True


def driver_shutdown():
    """
    Do the one-time driver shutdown
    """
    _shutdownFS()


def next_dataset( driver_config, driver_secrets ):
    """
    Return the next dataset command for the AG to process.
    Should block until there's data.

    Must call gateway.crawl() to feed the data into the AG.
    Return True if there are more datasets to process.
    Return False if not.
    """

    global command_queue

    # find the next command
    while True:
        # this will block if command is not immediately available
        cmd_sem = command_queue.get(True)
        cmd = cmd_sem[0]
        sem = cmd_sem[1]
        gateway.log_debug( "Processing a new command %s" % cmd['path'] )

        if cmd is not None:
            # send the command to the AG and get back the result
            rc = gateway.crawl( cmd )
            if rc != 0:
                gateway.log_error( "Failed to crawl %s" % cmd['path'] )

            command_queue.task_done()
            if sem:
                sem.release()
            gateway.log_debug( "Processed a command %s" % cmd['path'] )

            # have more data - wait for next commands
            return True
        else:
            # try next path
            gateway.log_error( "Could not fetch the command" )
            continue

    return False


def refresh( request, driver_config, driver_secrets ):
    """
    Request to refresh a particular path.
    Verify that it still exists, and if so,
    queue it for republishing.
    """

    global fs
    global command_queue

    path = gateway.request_path( request )
    file_path = gateway.path_join( "/", path )

    fs.clear_cache( file_path )
    cmd = None
    sem = threading.Semaphore()
    sem.acquire()

    if not fs.exists( file_path ):
        # delete
        gateway.log_debug( "No longer present: '%s'" % file_path )
        cmd = gateway.make_metadata_delete_command( file_path )
        gateway.log_debug( "Queuing a command %s" % cmd['path'] )
        command_queue.put( (cmd, sem) )
    else:
        # update
        gateway.log_debug( "Still present: '%s'" % file_path )
        stat = fs.stat( file_path )
        if not stat.directory:
            # file
            cmd = gateway.make_metadata_command( "put", "file", 0555, stat.size, file_path, read_ttl=DEFAULT_READ_TTL, write_ttl=DEFAULT_REFRESH_FILE_TTL )
            gateway.log_debug( "Queuing a command %s" % cmd['path'] )
            command_queue.put( (cmd, sem) )
        else:
            # directory
            cmd = gateway.make_metadata_command( "put", "directory", 0555, None, file_path, read_ttl=DEFAULT_READ_TTL, write_ttl=DEFAULT_REFRESH_DIRECTORY_TTL )
            gateway.log_debug( "Queuing a command %s" % cmd['path'] )
            command_queue.put( (cmd, sem) )

    # need to block until the queued command is processed
    gateway.log_debug( "Waiting for a new command to be processed" )
    # wait for semaphore release by next_dataset
    sem.acquire()
    # do nothing
    sem.release()
    #command_queue.join()

    return 0


def read( request, chunk_fd, driver_config, driver_secrets ):
    """
    Read a chunk of data.
    @request is a DriverRequest
    @chunk_fd is a file descriptor to which to write the data.
    @driver_config is a dict containing the driver's config
    @driver_secrets is a dict containing the driver's unencrypted secrets
    """

    global fs

    path = gateway.request_path( request )
    file_path = gateway.path_join( "/", path )
    byte_offset = gateway.request_byte_offset( request )
    byte_len = gateway.request_byte_len( request )

    if byte_offset is None:
        # this is a bug
        gateway.log_error( "BUG: byte offset of request on %s is not defined" % file_path )
        sys.exit( 1 )

    if byte_len is None:
        # this is a bug
        gateway.log_error( "BUG: byte len of request on %s is not defined" % file_path )
        sys.exit( 1 )

    if not fs.exists( file_path ):
        gateway.log_error( "No such file or directory: %s" % file_path )
        return -errno.ENOENT

    try:
        buf = fs.read( file_path, byte_offset, byte_len )
    except Exception, e:
        gateway.log_error( "Failed to read %s: %s" % ( file_path, e ) )
        return -errno.EREMOTEIO

    # send it off
    chunk_fd.write( buf )
    return 0
